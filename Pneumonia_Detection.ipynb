{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import pathlib\n",
    "import glob\n",
    "import os, os.path, shutil\n",
    "# Data Exploration\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "# Machine Learning\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "#Deep Learning\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import plot_model \n",
    "from keras import backend as K \n",
    "from keras import metrics\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, InputLayer, Activation\n",
    "from keras.preprocessing.image import img_to_array, ImageDataGenerator, array_to_img, load_img\n",
    "from keras.metrics import AUC\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pydot\n",
    "from dask import bag,  diagnostics\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show the image path\n",
    "data_1_NORMAL_dir = 'data_1/NORMAL/'\n",
    "data_1_PNEUMONIA_dir = 'data_1/PNEUMONIA/'\n",
    "new_dir = 'split/'\n",
    "# Create objects that stores all the relevant images\n",
    "images_NORMAL = [file for file in os.listdir(data_1_NORMAL_dir) if file.endswith('.jpeg')]\n",
    "images_PNEUMONIA = [file for file in os.listdir(data_1_PNEUMONIA_dir) if file.endswith('.jpeg')]\n",
    "# See how many images there in NORMAL directory and PNEUMONIA directory\n",
    "print('There are', len(images_NORMAL), 'NORMAL images')\n",
    "print('There are', len(images_PNEUMONIA), 'PNEUMONIA images')\n",
    "#Plot number of classes to identify imbalances\n",
    "number_classes = {'NORMAL':1583,\n",
    "                  'PNEUMONIA':4273}\n",
    "plt.bar(number_classes.keys(), number_classes.values(), width = 0.5)\n",
    "plt.title(\"Number of images by Class\")\n",
    "plt.xlabel(\"Class Name\")\n",
    "plt.ylabel(\"Numer of Images\")\n",
    "\n",
    "# Redo Train-Val-Test Split\n",
    "# Creat folders and subfolders to get a hierarchical file structure\n",
    "# Create a new folder 'split'\n",
    "os.mkdir(new_dir)\n",
    "\n",
    "# Create a subfolder 'train' under the 'split'\n",
    "train_folder = os.path.join(new_dir, 'train')\n",
    "# Create subfolders 'train_NORMAL' and 'train_PNEUMONIA' under the 'train'\n",
    "train_NORMAL = os.path.join(train_folder, 'NORMAL')\n",
    "train_PNEUMONIA = os.path.join(train_folder, 'PNEUMONIA')\n",
    "#___________________________________________________________________________\n",
    "# Create a subfolder 'test' under the 'split'\n",
    "test_folder = os.path.join(new_dir, 'test')\n",
    "# Create subfolders 'test_NORMAL' and 'test_PNEUMONIA' under the 'test'\n",
    "test_NORMAL = os.path.join(test_folder, 'NORMAL')\n",
    "test_PNEUMONIA = os.path.join(test_folder, 'PNEUMONIA')\n",
    "#___________________________________________________________________________\n",
    "# Create a subfolder 'test' under the 'split'\n",
    "val_folder = os.path.join(new_dir, 'validation')\n",
    "# # Create subfolders 'val_NORMAL' and 'val_PNEUMONIA' under the 'test'\n",
    "val_NORMAL = os.path.join(val_folder, 'NORMAL')\n",
    "val_PNEUMONIA = os.path.join(val_folder, 'PNEUMONIA')\n",
    "\n",
    "#Use all the path strings to make new directories\n",
    "os.mkdir(train_folder)\n",
    "os.mkdir(train_NORMAL)\n",
    "os.mkdir(train_PNEUMONIA)\n",
    "\n",
    "os.mkdir(test_folder)\n",
    "os.mkdir(test_NORMAL)\n",
    "os.mkdir(test_PNEUMONIA)\n",
    "\n",
    "os.mkdir(val_folder)\n",
    "os.mkdir(val_NORMAL)\n",
    "os.mkdir(val_PNEUMONIA)\n",
    "\n",
    "# Use a 70%/20%/10% split for train/validation/test\n",
    "print('Number of images to train')\n",
    "print('# train_NORMAL: ', round(len(images_NORMAL)*0.7))\n",
    "print('# train_PNEUMONIA: ', round(len(images_PNEUMONIA)*0.7))\n",
    "print('________________________________________________')\n",
    "print('Number of images to validation')\n",
    "print('# val_NORMAL: ', round(len(images_NORMAL)*0.2))\n",
    "print('# val_PNEUMONIA: ', round(len(images_PNEUMONIA)*0.2))\n",
    "print('________________________________________________')\n",
    "print('Number of images to test')\n",
    "print('# test_NORMAL: ', round(len(images_NORMAL)*0.1))\n",
    "print('# test_PNEUMONIA: ', round(len(images_PNEUMONIA)*0.1))\n",
    "\n",
    "#train NORMAL\n",
    "imgs = images_NORMAL[:1108]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_1_NORMAL_dir, img)\n",
    "    destination = os.path.join(train_NORMAL, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "# validation NORMAL\n",
    "imgs = images_NORMAL[1108:1425]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_1_NORMAL_dir, img)\n",
    "    destination = os.path.join(val_NORMAL, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "# test NORMAL\n",
    "imgs = images_NORMAL[1425:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_1_NORMAL_dir, img)\n",
    "    destination = os.path.join(test_NORMAL, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "    \n",
    "# train PNEUMONIA\n",
    "imgs = images_PNEUMONIA\n",
    "for img in imgs[:2991]:\n",
    "    origin = os.path.join(data_1_PNEUMONIA_dir, img)\n",
    "    destination = os.path.join(train_PNEUMONIA, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "# validation PNEUMONIA\n",
    "imgs = images_PNEUMONIA[2991:3846]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_1_PNEUMONIA_dir, img)\n",
    "    destination = os.path.join(val_PNEUMONIA, img)\n",
    "    shutil.copyfile(origin, destination)\n",
    "# test PNEUMONIA\n",
    "imgs = images_PNEUMONIA[3846:]\n",
    "for img in imgs:\n",
    "    origin = os.path.join(data_1_PNEUMONIA_dir, img)\n",
    "    destination = os.path.join(test_PNEUMONIA, img)\n",
    "    shutil.copyfile(origin, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data generator function\n",
    "\n",
    "def make_data_generator(\n",
    "    train_datagen, train_dir, \n",
    "    val_datagen, val_dir, \n",
    "    test_datagen, test_dir):\n",
    "    \n",
    "    datagen_lst = [train_datagen, val_datagen, test_datagen]\n",
    "    directory_lst = [train_dir, val_dir, test_dir]\n",
    "    generator_lst = []\n",
    "    for generator, directory in zip(datagen_lst, directory_lst):\n",
    "        if directory == train_dir:\n",
    "            shuffle = True\n",
    "        else:\n",
    "            shuffle = False\n",
    "        g = generator.flow_from_directory(directory = directory,\n",
    "                                         target_size = (64,64),\n",
    "                                         batch_size = 128,\n",
    "                                         color_mode = 'grayscale',\n",
    "                                         class_mode = 'binary',\n",
    "                                         shuffle = shuffle,\n",
    "                                         seed = 42)\n",
    "        generator_lst.append(g)\n",
    "    \n",
    "    return generator_lst\n",
    "  \n",
    "  # Load the images\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator,val_generator, test_generator = make_data_generator(\n",
    "    train_datagen, train_dir,\n",
    "    val_datagen, validation_dir,\n",
    "    test_datagen, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the model\n",
    "    \n",
    "def build_model_1():\n",
    "    cnn = Sequential()\n",
    "\n",
    "    cnn.add(InputLayer(input_shape=(64, 64, 1)))\n",
    "    cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn.add(MaxPooling2D((2, 2)))\n",
    "    cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn.add(MaxPooling2D((2, 2)))\n",
    "    cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    cnn.add(Flatten())\n",
    "\n",
    "    cnn.add(Dense(64, activation='relu'))\n",
    "    cnn.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile\n",
    "    cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "    return cnn\n",
    "\n",
    "cnn = build_model_1()\n",
    "\n",
    "# Train the model\n",
    "\n",
    "cnn_model = cnn.fit_generator(train_generator,\n",
    "                              epochs = 10,\n",
    "                              steps_per_epoch = len(train_generator),\n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = len(val_generator),\n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for plotting train and validation curve\n",
    "def train_validation_loss(cnn_model):\n",
    "    train_loss = cnn_model.history['loss']\n",
    "    val_loss = cnn_model.history['val_loss']\n",
    "    fig = plt.figure(figsize = (8,5))\n",
    "    plt.title(\"Training vs. Validation Loss\")\n",
    "    plt.plot(train_loss, label='training loss')\n",
    "    plt.plot(val_loss, label='validation loss')\n",
    "    plt.xlabel(\"Number of Epochs\", size=14)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for plotting train and validation curve\n",
    "def train_validation_acc(cnn_model):\n",
    "    train_loss = cnn_model.history['acc']\n",
    "    val_loss = cnn_model.history['val_acc']\n",
    "    fig = plt.figure(figsize = (8,5))\n",
    "    plt.title(\"Training vs. Validation Acc\")\n",
    "    plt.plot(train_loss, label='training acc')\n",
    "    plt.plot(val_loss, label='validation acc')\n",
    "    plt.xlabel(\"Number of Epochs\", size=14)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "def cm_plot_1(cnn):\n",
    "    y_true = test_generator.classes\n",
    "    Y_pred = cnn.predict_generator(test_generator, steps = len(test_generator))\n",
    "    y_pred = (Y_pred > 0.5).T[0]\n",
    "    y_pred_prob = Y_pred.T[0]\n",
    "    cm = confusion_matrix(y_true,y_pred,normalize = 'true')\n",
    "    plot_confusion_matrix(cm,figsize = (12,8), hide_ticks = True, cmap = plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\", fontsize = 22) \n",
    "    plt.xticks(range(2), ['Normal','Pneumonia'], fontsize = 16)\n",
    "    plt.yticks(range(2), ['Normal','Pneumonia'], fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_curve_AUC_score(cnn):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    y_true = test_generator.classes\n",
    "    Y_pred = cnn.predict_generator(test_generator, steps = len(test_generator))\n",
    "    y_pred = (Y_pred > 0.5).T[0]\n",
    "    y_pred_prob = Y_pred.T[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    plt.title('ROC Curve')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label = \"Random (AUC = 50%)\")\n",
    "    plt.plot(fpr, tpr, label='CNN (AUC = {:.2f}%)'.format(auc*100))\n",
    "    plt.xlabel('False Positive Rate', size=14)\n",
    "    plt.ylabel('True Positive Rate', size=14)\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summary_Stats(cnn):\n",
    "    y_true = test_generator.classes\n",
    "    Y_pred = cnn.predict_generator(test_generator, steps = len(test_generator))\n",
    "    y_pred = (Y_pred > 0.5).T[0]\n",
    "    y_pred_prob = Y_pred.T[0]\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    #############################\n",
    "    TN, FP, FN, TP = cm.ravel() # cm[0,0], cm[0, 1], cm[1, 0], cm[1, 1]\n",
    "    #ravel, which is used to change a 2-dimensional array or a multi-dimensional array into a contiguous flattened array. \n",
    "    #The returned array has the same data type as the source array or input array.\n",
    "    accuracy = (TP + TN) / np.sum(cm) \n",
    "    precision = TP / (TP+FP) \n",
    "    recall =  TP / (TP+FN)\n",
    "    specificity = TN / (TN+FP) \n",
    "    f1 = 2*precision*recall / (precision + recall)\n",
    "    stats_summary = '[Summary Statistics]\\nAccuracy = {:.2%} | Precision = {:.2%} | Recall = {:.2%} | Specificity = {:.2%} | F1 Score = {:.2%}'.format(accuracy, precision, recall, specificity, f1)\n",
    "    return stats_summary"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
